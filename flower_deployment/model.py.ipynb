{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "00-My-Basic-Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "E2W2F80WBi_5"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTfC-mGABi_c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYkCt-XtBi_e"
      },
      "source": [
        "# iris = pd.read_csv(\"../DATA/iris.csv\")\n",
        "iris  = pd.read_csv(\"iris.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "JTHYKrDaBi_e",
        "outputId": "b471d7fc-41a0-4fa8-fcff-994b96668a08"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzuVvokKBi_h"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnl9keH7Bi_i"
      },
      "source": [
        "### Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt1jsWJWBi_j",
        "outputId": "e44d0a7f-1597-4336-88b6-0784ca51a408"
      },
      "source": [
        "iris.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
              "       'species'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqSsnpqYBi_j"
      },
      "source": [
        "X = iris.drop('species',axis=1)\n",
        "y = iris['species']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDi8ssnZBi_k",
        "outputId": "6f34045b-0fda-4673-9a7b-b58510e16b20"
      },
      "source": [
        "iris['species'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp_hrxtkBi_l"
      },
      "source": [
        "# Lots of ways to one hot encode\n",
        "# https://stackoverflow.com/questions/47573293/unable-to-transform-string-column-to-categorical-matrix-using-keras-and-sklearn\n",
        "# https://stackoverflow.com/questions/35107559/one-hot-encoding-of-string-categorical-features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZibsYYNBi_m"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()\n",
        "y = encoder.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJTeGnZ3Bi_n"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr0vXUtNBi_n"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbsQ5uOKBi_o"
      },
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsWKg5tRBi_o"
      },
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A60g6MNBBi_q",
        "outputId": "7304e4ac-f0b3-41b5-984e-1c9e758c409b"
      },
      "source": [
        "scaler.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGdDto1FBi_r"
      },
      "source": [
        "scaled_X_train = scaler.transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rheHDLwvBi_s"
      },
      "source": [
        "scaled_X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrrCsqcJBi_s"
      },
      "source": [
        "## Model\n",
        "\n",
        "\n",
        "### Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQEMemchBi_t"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pWcJ1MkBi_u"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
        "\n",
        "# Last layer for multi-class classification of 3 species\n",
        "model.add(Dense(units=3,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4qXmLOHBi_u"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAe0T169Bi_v"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebvhstZyBi_v"
      },
      "source": [
        "early_stop = EarlyStopping(patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUsovDbzBi_w",
        "outputId": "c9a74bcf-d61b-47af-904c-1df063b809c2"
      },
      "source": [
        "model.fit(x=scaled_X_train, \n",
        "          y=y_train, \n",
        "          epochs=300,\n",
        "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop]         )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 1.1957 - accuracy: 0.3398 - val_loss: 1.1809 - val_accuracy: 0.4000\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.1867 - accuracy: 0.3148 - val_loss: 1.1738 - val_accuracy: 0.4000\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.1789 - accuracy: 0.3060 - val_loss: 1.1668 - val_accuracy: 0.4000\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.1416 - accuracy: 0.3519 - val_loss: 1.1603 - val_accuracy: 0.4000\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.1548 - accuracy: 0.3258 - val_loss: 1.1541 - val_accuracy: 0.4000\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.1345 - accuracy: 0.3165 - val_loss: 1.1482 - val_accuracy: 0.4000\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.1573 - accuracy: 0.2706 - val_loss: 1.1424 - val_accuracy: 0.4000\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.1226 - accuracy: 0.3321 - val_loss: 1.1370 - val_accuracy: 0.4000\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.1238 - accuracy: 0.3237 - val_loss: 1.1316 - val_accuracy: 0.4000\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.1241 - accuracy: 0.3321 - val_loss: 1.1262 - val_accuracy: 0.4000\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.1214 - accuracy: 0.2987 - val_loss: 1.1209 - val_accuracy: 0.4333\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.1072 - accuracy: 0.3154 - val_loss: 1.1159 - val_accuracy: 0.4333\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.1153 - accuracy: 0.2717 - val_loss: 1.1107 - val_accuracy: 0.4333\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.1074 - accuracy: 0.3040 - val_loss: 1.1058 - val_accuracy: 0.4333\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.0996 - accuracy: 0.3165 - val_loss: 1.1009 - val_accuracy: 0.4333\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.0846 - accuracy: 0.3133 - val_loss: 1.0962 - val_accuracy: 0.4333\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.0808 - accuracy: 0.3642 - val_loss: 1.0914 - val_accuracy: 0.4333\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.0668 - accuracy: 0.3352 - val_loss: 1.0867 - val_accuracy: 0.4333\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.0852 - accuracy: 0.3198 - val_loss: 1.0819 - val_accuracy: 0.4333\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.0786 - accuracy: 0.3483 - val_loss: 1.0772 - val_accuracy: 0.4333\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.0653 - accuracy: 0.3356 - val_loss: 1.0726 - val_accuracy: 0.4333\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.0543 - accuracy: 0.3754 - val_loss: 1.0681 - val_accuracy: 0.4667\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.0548 - accuracy: 0.3465 - val_loss: 1.0635 - val_accuracy: 0.4667\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.0532 - accuracy: 0.3417 - val_loss: 1.0590 - val_accuracy: 0.4667\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.0363 - accuracy: 0.4010 - val_loss: 1.0547 - val_accuracy: 0.4667\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.0517 - accuracy: 0.3769 - val_loss: 1.0502 - val_accuracy: 0.4667\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.0316 - accuracy: 0.4219 - val_loss: 1.0461 - val_accuracy: 0.4333\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.0332 - accuracy: 0.4400 - val_loss: 1.0418 - val_accuracy: 0.4667\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.0200 - accuracy: 0.4319 - val_loss: 1.0377 - val_accuracy: 0.5000\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.0118 - accuracy: 0.4833 - val_loss: 1.0336 - val_accuracy: 0.4667\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.0142 - accuracy: 0.5062 - val_loss: 1.0294 - val_accuracy: 0.4667\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.0133 - accuracy: 0.4817 - val_loss: 1.0251 - val_accuracy: 0.4333\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.0068 - accuracy: 0.4596 - val_loss: 1.0210 - val_accuracy: 0.4333\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.0043 - accuracy: 0.4248 - val_loss: 1.0167 - val_accuracy: 0.5000\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.0017 - accuracy: 0.4398 - val_loss: 1.0125 - val_accuracy: 0.4667\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.9937 - accuracy: 0.4848 - val_loss: 1.0084 - val_accuracy: 0.4333\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.9891 - accuracy: 0.4742 - val_loss: 1.0045 - val_accuracy: 0.4000\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.9803 - accuracy: 0.5325 - val_loss: 1.0008 - val_accuracy: 0.4333\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.9785 - accuracy: 0.5354 - val_loss: 0.9970 - val_accuracy: 0.4333\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.9722 - accuracy: 0.6077 - val_loss: 0.9933 - val_accuracy: 0.4333\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.9701 - accuracy: 0.6017 - val_loss: 0.9895 - val_accuracy: 0.4667\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9689 - accuracy: 0.6052 - val_loss: 0.9858 - val_accuracy: 0.5333\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9586 - accuracy: 0.6325 - val_loss: 0.9823 - val_accuracy: 0.5333\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.9574 - accuracy: 0.6673 - val_loss: 0.9788 - val_accuracy: 0.5333\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.9488 - accuracy: 0.6946 - val_loss: 0.9754 - val_accuracy: 0.5333\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9498 - accuracy: 0.6373 - val_loss: 0.9718 - val_accuracy: 0.5667\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9414 - accuracy: 0.6592 - val_loss: 0.9683 - val_accuracy: 0.6000\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9417 - accuracy: 0.6654 - val_loss: 0.9648 - val_accuracy: 0.6000\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.9390 - accuracy: 0.6467 - val_loss: 0.9613 - val_accuracy: 0.6000\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.9373 - accuracy: 0.6177 - val_loss: 0.9578 - val_accuracy: 0.6000\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.9302 - accuracy: 0.6856 - val_loss: 0.9543 - val_accuracy: 0.6000\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.9242 - accuracy: 0.6879 - val_loss: 0.9507 - val_accuracy: 0.6000\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.9207 - accuracy: 0.6598 - val_loss: 0.9471 - val_accuracy: 0.6000\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.9158 - accuracy: 0.6837 - val_loss: 0.9434 - val_accuracy: 0.6000\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.9043 - accuracy: 0.7129 - val_loss: 0.9398 - val_accuracy: 0.6000\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.9072 - accuracy: 0.6733 - val_loss: 0.9360 - val_accuracy: 0.6000\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.9029 - accuracy: 0.6910 - val_loss: 0.9321 - val_accuracy: 0.6000\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.8972 - accuracy: 0.6619 - val_loss: 0.9283 - val_accuracy: 0.6000\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.8886 - accuracy: 0.7056 - val_loss: 0.9245 - val_accuracy: 0.6000\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.9032 - accuracy: 0.6192 - val_loss: 0.9206 - val_accuracy: 0.6000\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.8925 - accuracy: 0.6515 - val_loss: 0.9168 - val_accuracy: 0.6000\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.8868 - accuracy: 0.6608 - val_loss: 0.9131 - val_accuracy: 0.6000\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.8815 - accuracy: 0.6712 - val_loss: 0.9093 - val_accuracy: 0.6000\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.8739 - accuracy: 0.6681 - val_loss: 0.9055 - val_accuracy: 0.6000\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8614 - accuracy: 0.7098 - val_loss: 0.9018 - val_accuracy: 0.6000\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.8635 - accuracy: 0.6942 - val_loss: 0.8979 - val_accuracy: 0.6000\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8548 - accuracy: 0.6994 - val_loss: 0.8941 - val_accuracy: 0.6000\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.8492 - accuracy: 0.7035 - val_loss: 0.8903 - val_accuracy: 0.6000\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.8532 - accuracy: 0.6890 - val_loss: 0.8866 - val_accuracy: 0.6000\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.7035 - val_loss: 0.8827 - val_accuracy: 0.6000\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.8404 - accuracy: 0.6900 - val_loss: 0.8789 - val_accuracy: 0.6000\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8388 - accuracy: 0.6817 - val_loss: 0.8750 - val_accuracy: 0.6000\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.8227 - accuracy: 0.7285 - val_loss: 0.8715 - val_accuracy: 0.6000\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.8397 - accuracy: 0.6619 - val_loss: 0.8678 - val_accuracy: 0.6000\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.8328 - accuracy: 0.6598 - val_loss: 0.8642 - val_accuracy: 0.6000\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.8211 - accuracy: 0.6765 - val_loss: 0.8604 - val_accuracy: 0.6000\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.8212 - accuracy: 0.6712 - val_loss: 0.8566 - val_accuracy: 0.6000\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.8118 - accuracy: 0.6952 - val_loss: 0.8528 - val_accuracy: 0.6000\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8191 - accuracy: 0.6629 - val_loss: 0.8487 - val_accuracy: 0.6000\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.8033 - accuracy: 0.6827 - val_loss: 0.8445 - val_accuracy: 0.6000\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7771 - accuracy: 0.7379 - val_loss: 0.8407 - val_accuracy: 0.6000\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.8031 - accuracy: 0.6442 - val_loss: 0.8365 - val_accuracy: 0.6000\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.7836 - accuracy: 0.7129 - val_loss: 0.8326 - val_accuracy: 0.6000\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.7825 - accuracy: 0.6962 - val_loss: 0.8285 - val_accuracy: 0.6000\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7865 - accuracy: 0.6660 - val_loss: 0.8244 - val_accuracy: 0.6000\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7730 - accuracy: 0.7129 - val_loss: 0.8205 - val_accuracy: 0.6000\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7584 - accuracy: 0.7150 - val_loss: 0.8167 - val_accuracy: 0.6000\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7548 - accuracy: 0.7077 - val_loss: 0.8126 - val_accuracy: 0.6000\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7604 - accuracy: 0.6879 - val_loss: 0.8086 - val_accuracy: 0.6000\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7573 - accuracy: 0.6900 - val_loss: 0.8046 - val_accuracy: 0.6000\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7672 - accuracy: 0.6587 - val_loss: 0.8005 - val_accuracy: 0.6000\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7666 - accuracy: 0.6473 - val_loss: 0.7965 - val_accuracy: 0.6000\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.7475 - accuracy: 0.6660 - val_loss: 0.7927 - val_accuracy: 0.6000\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7328 - accuracy: 0.7129 - val_loss: 0.7892 - val_accuracy: 0.6000\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7389 - accuracy: 0.6650 - val_loss: 0.7852 - val_accuracy: 0.6000\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7323 - accuracy: 0.6942 - val_loss: 0.7815 - val_accuracy: 0.6000\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7267 - accuracy: 0.7067 - val_loss: 0.7778 - val_accuracy: 0.6000\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.7116 - accuracy: 0.7181 - val_loss: 0.7739 - val_accuracy: 0.6000\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.7374 - accuracy: 0.6525 - val_loss: 0.7699 - val_accuracy: 0.6000\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6996 - accuracy: 0.7306 - val_loss: 0.7662 - val_accuracy: 0.6000\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.7198 - accuracy: 0.6567 - val_loss: 0.7621 - val_accuracy: 0.6000\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.7237 - accuracy: 0.6494 - val_loss: 0.7583 - val_accuracy: 0.6000\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.7180 - accuracy: 0.6577 - val_loss: 0.7548 - val_accuracy: 0.6000\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6889 - accuracy: 0.7181 - val_loss: 0.7514 - val_accuracy: 0.6000\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6986 - accuracy: 0.6650 - val_loss: 0.7478 - val_accuracy: 0.6000\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6979 - accuracy: 0.6785 - val_loss: 0.7443 - val_accuracy: 0.6000\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6874 - accuracy: 0.6900 - val_loss: 0.7408 - val_accuracy: 0.6000\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6807 - accuracy: 0.6921 - val_loss: 0.7374 - val_accuracy: 0.6000\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.7060 - accuracy: 0.6431 - val_loss: 0.7337 - val_accuracy: 0.6000\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6809 - accuracy: 0.6806 - val_loss: 0.7303 - val_accuracy: 0.6333\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6797 - accuracy: 0.6619 - val_loss: 0.7268 - val_accuracy: 0.6333\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6554 - accuracy: 0.7202 - val_loss: 0.7237 - val_accuracy: 0.6333\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6646 - accuracy: 0.6754 - val_loss: 0.7200 - val_accuracy: 0.6333\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6586 - accuracy: 0.7069 - val_loss: 0.7165 - val_accuracy: 0.6333\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6463 - accuracy: 0.6954 - val_loss: 0.7130 - val_accuracy: 0.6333\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6513 - accuracy: 0.7090 - val_loss: 0.7098 - val_accuracy: 0.6333\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6661 - accuracy: 0.6871 - val_loss: 0.7065 - val_accuracy: 0.6333\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6409 - accuracy: 0.7048 - val_loss: 0.7033 - val_accuracy: 0.6333\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6389 - accuracy: 0.7038 - val_loss: 0.7000 - val_accuracy: 0.6333\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6354 - accuracy: 0.7027 - val_loss: 0.6967 - val_accuracy: 0.6333\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6390 - accuracy: 0.6996 - val_loss: 0.6934 - val_accuracy: 0.6333\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6516 - accuracy: 0.6683 - val_loss: 0.6901 - val_accuracy: 0.6333\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6341 - accuracy: 0.6821 - val_loss: 0.6868 - val_accuracy: 0.6333\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6421 - accuracy: 0.6790 - val_loss: 0.6835 - val_accuracy: 0.6333\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6273 - accuracy: 0.6800 - val_loss: 0.6802 - val_accuracy: 0.6333\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6210 - accuracy: 0.7092 - val_loss: 0.6772 - val_accuracy: 0.6333\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6134 - accuracy: 0.7154 - val_loss: 0.6742 - val_accuracy: 0.6333\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6388 - accuracy: 0.6571 - val_loss: 0.6709 - val_accuracy: 0.6333\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6223 - accuracy: 0.7050 - val_loss: 0.6679 - val_accuracy: 0.6333\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6195 - accuracy: 0.6998 - val_loss: 0.6650 - val_accuracy: 0.6333\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6210 - accuracy: 0.6967 - val_loss: 0.6621 - val_accuracy: 0.6333\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6253 - accuracy: 0.6708 - val_loss: 0.6590 - val_accuracy: 0.6333\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5803 - accuracy: 0.7208 - val_loss: 0.6561 - val_accuracy: 0.6333\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5868 - accuracy: 0.7167 - val_loss: 0.6533 - val_accuracy: 0.6333\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5826 - accuracy: 0.7125 - val_loss: 0.6505 - val_accuracy: 0.6333\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5990 - accuracy: 0.6833 - val_loss: 0.6476 - val_accuracy: 0.6667\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5950 - accuracy: 0.7042 - val_loss: 0.6445 - val_accuracy: 0.6667\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5836 - accuracy: 0.7106 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5733 - accuracy: 0.7463 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5661 - accuracy: 0.7527 - val_loss: 0.6359 - val_accuracy: 0.6667\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5926 - accuracy: 0.7110 - val_loss: 0.6331 - val_accuracy: 0.6667\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6200 - accuracy: 0.6663 - val_loss: 0.6302 - val_accuracy: 0.6667\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5665 - accuracy: 0.7340 - val_loss: 0.6276 - val_accuracy: 0.6667\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5630 - accuracy: 0.7558 - val_loss: 0.6251 - val_accuracy: 0.6667\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5467 - accuracy: 0.7883 - val_loss: 0.6226 - val_accuracy: 0.6667\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5948 - accuracy: 0.7146 - val_loss: 0.6196 - val_accuracy: 0.6667\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5542 - accuracy: 0.7844 - val_loss: 0.6170 - val_accuracy: 0.6667\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5354 - accuracy: 0.7702 - val_loss: 0.6142 - val_accuracy: 0.7000\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5524 - accuracy: 0.7671 - val_loss: 0.6114 - val_accuracy: 0.7000\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5570 - accuracy: 0.7577 - val_loss: 0.6087 - val_accuracy: 0.7667\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5380 - accuracy: 0.7685 - val_loss: 0.6060 - val_accuracy: 0.7667\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5547 - accuracy: 0.7948 - val_loss: 0.6035 - val_accuracy: 0.7667\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5461 - accuracy: 0.7958 - val_loss: 0.6011 - val_accuracy: 0.8000\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5513 - accuracy: 0.7760 - val_loss: 0.5985 - val_accuracy: 0.8000\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5591 - accuracy: 0.7448 - val_loss: 0.5960 - val_accuracy: 0.8000\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5302 - accuracy: 0.8044 - val_loss: 0.5937 - val_accuracy: 0.8000\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5402 - accuracy: 0.8158 - val_loss: 0.5913 - val_accuracy: 0.8000\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5491 - accuracy: 0.7908 - val_loss: 0.5889 - val_accuracy: 0.8000\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5403 - accuracy: 0.8129 - val_loss: 0.5865 - val_accuracy: 0.8000\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4968 - accuracy: 0.8442 - val_loss: 0.5841 - val_accuracy: 0.8000\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5283 - accuracy: 0.8223 - val_loss: 0.5817 - val_accuracy: 0.8000\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5365 - accuracy: 0.7775 - val_loss: 0.5792 - val_accuracy: 0.8000\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5336 - accuracy: 0.7858 - val_loss: 0.5769 - val_accuracy: 0.8000\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5168 - accuracy: 0.8233 - val_loss: 0.5747 - val_accuracy: 0.8000\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5335 - accuracy: 0.7858 - val_loss: 0.5724 - val_accuracy: 0.8000\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5069 - accuracy: 0.8337 - val_loss: 0.5703 - val_accuracy: 0.8000\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5060 - accuracy: 0.7994 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5319 - accuracy: 0.7694 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5043 - accuracy: 0.8373 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5215 - accuracy: 0.8362 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5053 - accuracy: 0.8227 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5011 - accuracy: 0.8008 - val_loss: 0.5566 - val_accuracy: 0.8000\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4887 - accuracy: 0.8458 - val_loss: 0.5544 - val_accuracy: 0.8000\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4803 - accuracy: 0.8552 - val_loss: 0.5523 - val_accuracy: 0.8000\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5016 - accuracy: 0.8115 - val_loss: 0.5503 - val_accuracy: 0.8000\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5258 - accuracy: 0.7948 - val_loss: 0.5480 - val_accuracy: 0.8000\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4967 - accuracy: 0.8167 - val_loss: 0.5461 - val_accuracy: 0.8000\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4954 - accuracy: 0.8242 - val_loss: 0.5441 - val_accuracy: 0.8000\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4976 - accuracy: 0.8356 - val_loss: 0.5421 - val_accuracy: 0.8000\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4862 - accuracy: 0.8450 - val_loss: 0.5401 - val_accuracy: 0.8000\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4825 - accuracy: 0.8408 - val_loss: 0.5380 - val_accuracy: 0.8000\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4883 - accuracy: 0.8200 - val_loss: 0.5359 - val_accuracy: 0.8000\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4710 - accuracy: 0.8325 - val_loss: 0.5338 - val_accuracy: 0.8000\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4665 - accuracy: 0.8648 - val_loss: 0.5319 - val_accuracy: 0.8000\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5072 - accuracy: 0.8190 - val_loss: 0.5299 - val_accuracy: 0.8000\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4866 - accuracy: 0.8356 - val_loss: 0.5281 - val_accuracy: 0.8000\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4762 - accuracy: 0.8367 - val_loss: 0.5262 - val_accuracy: 0.8000\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4764 - accuracy: 0.8450 - val_loss: 0.5244 - val_accuracy: 0.8000\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4678 - accuracy: 0.8504 - val_loss: 0.5225 - val_accuracy: 0.8000\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4550 - accuracy: 0.8773 - val_loss: 0.5208 - val_accuracy: 0.8000\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4612 - accuracy: 0.8640 - val_loss: 0.5189 - val_accuracy: 0.8000\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4718 - accuracy: 0.8421 - val_loss: 0.5168 - val_accuracy: 0.8333\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4610 - accuracy: 0.8327 - val_loss: 0.5149 - val_accuracy: 0.8333\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4620 - accuracy: 0.8588 - val_loss: 0.5132 - val_accuracy: 0.8333\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4534 - accuracy: 0.8504 - val_loss: 0.5115 - val_accuracy: 0.8333\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4626 - accuracy: 0.8421 - val_loss: 0.5097 - val_accuracy: 0.8333\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4640 - accuracy: 0.8538 - val_loss: 0.5079 - val_accuracy: 0.8333\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4768 - accuracy: 0.8342 - val_loss: 0.5061 - val_accuracy: 0.8333\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4691 - accuracy: 0.8342 - val_loss: 0.5045 - val_accuracy: 0.8333\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4548 - accuracy: 0.8435 - val_loss: 0.5030 - val_accuracy: 0.8333\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4245 - accuracy: 0.8652 - val_loss: 0.5016 - val_accuracy: 0.8333\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4446 - accuracy: 0.8652 - val_loss: 0.4999 - val_accuracy: 0.8333\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4395 - accuracy: 0.8810 - val_loss: 0.4982 - val_accuracy: 0.8333\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4444 - accuracy: 0.8696 - val_loss: 0.4965 - val_accuracy: 0.8333\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4449 - accuracy: 0.8677 - val_loss: 0.4946 - val_accuracy: 0.8333\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4656 - accuracy: 0.8719 - val_loss: 0.4928 - val_accuracy: 0.8333\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4513 - accuracy: 0.8552 - val_loss: 0.4913 - val_accuracy: 0.8333\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4297 - accuracy: 0.8740 - val_loss: 0.4898 - val_accuracy: 0.8333\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4611 - accuracy: 0.8688 - val_loss: 0.4881 - val_accuracy: 0.8333\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4372 - accuracy: 0.8469 - val_loss: 0.4864 - val_accuracy: 0.8667\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4529 - accuracy: 0.8460 - val_loss: 0.4847 - val_accuracy: 0.8667\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4286 - accuracy: 0.8867 - val_loss: 0.4833 - val_accuracy: 0.8667\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4535 - accuracy: 0.8867 - val_loss: 0.4817 - val_accuracy: 0.8667\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4294 - accuracy: 0.9044 - val_loss: 0.4803 - val_accuracy: 0.8667\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4318 - accuracy: 0.8971 - val_loss: 0.4788 - val_accuracy: 0.8667\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4085 - accuracy: 0.8950 - val_loss: 0.4771 - val_accuracy: 0.8667\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4113 - accuracy: 0.8950 - val_loss: 0.4754 - val_accuracy: 0.8667\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4229 - accuracy: 0.8752 - val_loss: 0.4738 - val_accuracy: 0.8667\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3932 - accuracy: 0.9085 - val_loss: 0.4724 - val_accuracy: 0.8667\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4142 - accuracy: 0.9096 - val_loss: 0.4708 - val_accuracy: 0.9000\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4267 - accuracy: 0.8750 - val_loss: 0.4692 - val_accuracy: 0.9000\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4203 - accuracy: 0.8656 - val_loss: 0.4675 - val_accuracy: 0.9000\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4145 - accuracy: 0.8865 - val_loss: 0.4661 - val_accuracy: 0.9000\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4429 - accuracy: 0.8385 - val_loss: 0.4645 - val_accuracy: 0.9000\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3965 - accuracy: 0.8833 - val_loss: 0.4632 - val_accuracy: 0.9000\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4041 - accuracy: 0.9104 - val_loss: 0.4618 - val_accuracy: 0.9000\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3958 - accuracy: 0.9104 - val_loss: 0.4605 - val_accuracy: 0.9000\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4327 - accuracy: 0.8656 - val_loss: 0.4588 - val_accuracy: 0.9000\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3872 - accuracy: 0.8771 - val_loss: 0.4574 - val_accuracy: 0.9000\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3864 - accuracy: 0.9021 - val_loss: 0.4563 - val_accuracy: 0.9000\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4218 - accuracy: 0.8750 - val_loss: 0.4546 - val_accuracy: 0.9000\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4104 - accuracy: 0.8933 - val_loss: 0.4532 - val_accuracy: 0.9000\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4099 - accuracy: 0.9152 - val_loss: 0.4520 - val_accuracy: 0.9000\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3985 - accuracy: 0.9235 - val_loss: 0.4506 - val_accuracy: 0.9000\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4360 - accuracy: 0.8787 - val_loss: 0.4493 - val_accuracy: 0.9000\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3803 - accuracy: 0.9162 - val_loss: 0.4481 - val_accuracy: 0.9000\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4139 - accuracy: 0.9058 - val_loss: 0.4467 - val_accuracy: 0.9000\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3930 - accuracy: 0.8985 - val_loss: 0.4453 - val_accuracy: 0.9000\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3940 - accuracy: 0.9110 - val_loss: 0.4440 - val_accuracy: 0.9000\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4024 - accuracy: 0.8787 - val_loss: 0.4426 - val_accuracy: 0.9000\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3809 - accuracy: 0.9079 - val_loss: 0.4413 - val_accuracy: 0.9000\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3733 - accuracy: 0.9277 - val_loss: 0.4399 - val_accuracy: 0.9000\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4161 - accuracy: 0.8892 - val_loss: 0.4384 - val_accuracy: 0.9000\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3874 - accuracy: 0.9183 - val_loss: 0.4373 - val_accuracy: 0.9000\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3742 - accuracy: 0.9027 - val_loss: 0.4359 - val_accuracy: 0.9000\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4114 - accuracy: 0.8798 - val_loss: 0.4347 - val_accuracy: 0.9000\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3997 - accuracy: 0.8787 - val_loss: 0.4335 - val_accuracy: 0.9000\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3725 - accuracy: 0.9037 - val_loss: 0.4322 - val_accuracy: 0.9000\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3934 - accuracy: 0.8808 - val_loss: 0.4310 - val_accuracy: 0.9000\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3902 - accuracy: 0.8871 - val_loss: 0.4299 - val_accuracy: 0.9000\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3767 - accuracy: 0.9194 - val_loss: 0.4288 - val_accuracy: 0.9000\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3946 - accuracy: 0.9006 - val_loss: 0.4275 - val_accuracy: 0.9000\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3635 - accuracy: 0.9319 - val_loss: 0.4262 - val_accuracy: 0.9000\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3664 - accuracy: 0.8975 - val_loss: 0.4251 - val_accuracy: 0.9000\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3807 - accuracy: 0.9040 - val_loss: 0.4237 - val_accuracy: 0.9000\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3825 - accuracy: 0.9071 - val_loss: 0.4225 - val_accuracy: 0.9000\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4028 - accuracy: 0.9019 - val_loss: 0.4213 - val_accuracy: 0.9000\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3610 - accuracy: 0.9227 - val_loss: 0.4202 - val_accuracy: 0.9000\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3616 - accuracy: 0.9331 - val_loss: 0.4191 - val_accuracy: 0.9000\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3784 - accuracy: 0.9154 - val_loss: 0.4179 - val_accuracy: 0.9000\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3657 - accuracy: 0.9040 - val_loss: 0.4167 - val_accuracy: 0.9000\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3709 - accuracy: 0.9206 - val_loss: 0.4153 - val_accuracy: 0.9000\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3722 - accuracy: 0.9133 - val_loss: 0.4141 - val_accuracy: 0.9333\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3789 - accuracy: 0.9029 - val_loss: 0.4129 - val_accuracy: 0.9333\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3838 - accuracy: 0.8925 - val_loss: 0.4117 - val_accuracy: 0.9333\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3509 - accuracy: 0.9206 - val_loss: 0.4107 - val_accuracy: 0.9333\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3665 - accuracy: 0.8894 - val_loss: 0.4096 - val_accuracy: 0.9333\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3593 - accuracy: 0.9310 - val_loss: 0.4085 - val_accuracy: 0.9333\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3523 - accuracy: 0.9217 - val_loss: 0.4074 - val_accuracy: 0.9333\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3543 - accuracy: 0.9102 - val_loss: 0.4063 - val_accuracy: 0.9333\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3675 - accuracy: 0.8935 - val_loss: 0.4053 - val_accuracy: 0.9333\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3849 - accuracy: 0.8852 - val_loss: 0.4042 - val_accuracy: 0.9333\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3642 - accuracy: 0.9071 - val_loss: 0.4031 - val_accuracy: 0.9333\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3374 - accuracy: 0.9385 - val_loss: 0.4021 - val_accuracy: 0.9333\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3618 - accuracy: 0.9240 - val_loss: 0.4011 - val_accuracy: 0.9333\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3576 - accuracy: 0.9156 - val_loss: 0.4001 - val_accuracy: 0.9333\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3543 - accuracy: 0.9198 - val_loss: 0.3991 - val_accuracy: 0.9333\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3785 - accuracy: 0.9083 - val_loss: 0.3980 - val_accuracy: 0.9333\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3337 - accuracy: 0.9354 - val_loss: 0.3970 - val_accuracy: 0.9333\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3741 - accuracy: 0.8917 - val_loss: 0.3960 - val_accuracy: 0.9333\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3517 - accuracy: 0.9177 - val_loss: 0.3951 - val_accuracy: 0.9333\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3408 - accuracy: 0.9240 - val_loss: 0.3939 - val_accuracy: 0.9333\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3367 - accuracy: 0.9396 - val_loss: 0.3929 - val_accuracy: 0.9333\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3633 - accuracy: 0.9167 - val_loss: 0.3919 - val_accuracy: 0.9333\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3462 - accuracy: 0.9156 - val_loss: 0.3909 - val_accuracy: 0.9333\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3236 - accuracy: 0.9365 - val_loss: 0.3898 - val_accuracy: 0.9333\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3481 - accuracy: 0.9010 - val_loss: 0.3888 - val_accuracy: 0.9333\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3389 - accuracy: 0.9281 - val_loss: 0.3878 - val_accuracy: 0.9333\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3645 - accuracy: 0.9042 - val_loss: 0.3868 - val_accuracy: 0.9333\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3547 - accuracy: 0.9146 - val_loss: 0.3858 - val_accuracy: 0.9333\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3491 - accuracy: 0.9219 - val_loss: 0.3849 - val_accuracy: 0.9333\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3593 - accuracy: 0.9104 - val_loss: 0.3839 - val_accuracy: 0.9333\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3598 - accuracy: 0.9198 - val_loss: 0.3830 - val_accuracy: 0.9333\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3423 - accuracy: 0.9104 - val_loss: 0.3822 - val_accuracy: 0.9333\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3253 - accuracy: 0.9417 - val_loss: 0.3813 - val_accuracy: 0.9333\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3591 - accuracy: 0.9031 - val_loss: 0.3803 - val_accuracy: 0.9333\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3521 - accuracy: 0.9010 - val_loss: 0.3795 - val_accuracy: 0.9333\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3431 - accuracy: 0.9156 - val_loss: 0.3785 - val_accuracy: 0.9333\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3522 - accuracy: 0.8958 - val_loss: 0.3777 - val_accuracy: 0.9333\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3254 - accuracy: 0.9281 - val_loss: 0.3767 - val_accuracy: 0.9333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3a016efe50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4IePZU7Bi_x"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R4k0sJ5Bi_x"
      },
      "source": [
        "metrics = pd.DataFrame(model.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "KRc35FzyBi_y",
        "outputId": "d472b63c-db65-436f-e188-703900de34b5"
      },
      "source": [
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.182682</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.180873</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.175237</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.173782</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.168105</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>1.166843</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.160630</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>1.160323</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.154334</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>1.154061</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>0.340262</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.380325</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0.339254</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.379466</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>0.338445</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.378541</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.337618</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.377676</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>0.336765</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.376721</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows  4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  accuracy  val_loss  val_accuracy\n",
              "0    1.182682  0.341667  1.180873      0.400000\n",
              "1    1.175237  0.341667  1.173782      0.400000\n",
              "2    1.168105  0.325000  1.166843      0.400000\n",
              "3    1.160630  0.325000  1.160323      0.400000\n",
              "4    1.154334  0.325000  1.154061      0.400000\n",
              "..        ...       ...       ...           ...\n",
              "295  0.340262  0.916667  0.380325      0.933333\n",
              "296  0.339254  0.916667  0.379466      0.933333\n",
              "297  0.338445  0.916667  0.378541      0.933333\n",
              "298  0.337618  0.916667  0.377676      0.933333\n",
              "299  0.336765  0.916667  0.376721      0.933333\n",
              "\n",
              "[300 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "CMIaUNdkBi_z",
        "outputId": "4224f83b-c856-4056-b2a2-37862ca13d31"
      },
      "source": [
        "metrics[['loss','val_loss']].plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f39fddf4990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fJYCOIB1Bi_z",
        "outputId": "a815ce16-2c32-4016-d3cf-70b0b1b94f34"
      },
      "source": [
        "metrics[['accuracy','val_accuracy']].plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f39fdceed90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt_y40b2Bi_0",
        "outputId": "0f4817ac-aa13-4302-addf-45da3ec7fab6"
      },
      "source": [
        "model.evaluate(scaled_X_test,y_test,verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3767208456993103, 0.9333333373069763]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZlPTmXZBi_1"
      },
      "source": [
        "## Ready Model for Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE5aPMNPBi_1"
      },
      "source": [
        "epochs = len(metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK0av8ZhBi_2"
      },
      "source": [
        "scaled_X = scaler.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_trJGAaBi_2"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=4,activation='relu'))\n",
        "\n",
        "# Last layer for multi-class classification of 3 species\n",
        "model.add(Dense(units=3,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L3OxYNMBi_3",
        "outputId": "998c11e8-7568-4800-b8e4-4ac2180163aa"
      },
      "source": [
        "model.fit(scaled_X,y,epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4321 - accuracy: 0.3212\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.4828 - accuracy: 0.2886\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4775 - accuracy: 0.2986\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4018 - accuracy: 0.3229\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4397 - accuracy: 0.2760\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3551 - accuracy: 0.3124\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3789 - accuracy: 0.3120\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3129 - accuracy: 0.3567\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3517 - accuracy: 0.3385\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3256 - accuracy: 0.3242\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3775 - accuracy: 0.2916\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3025 - accuracy: 0.3033\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2858 - accuracy: 0.3285\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3289 - accuracy: 0.2914\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2946 - accuracy: 0.2486\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2748 - accuracy: 0.2177\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.2827 - accuracy: 0.2406\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2575 - accuracy: 0.2083\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2530 - accuracy: 0.2069\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2101 - accuracy: 0.1654\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2421 - accuracy: 0.1431\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2096 - accuracy: 0.1559\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2054 - accuracy: 0.1033\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2047 - accuracy: 0.0849\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.2016 - accuracy: 0.0814\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1787 - accuracy: 0.1144\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1824 - accuracy: 0.0882\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1944 - accuracy: 0.0804\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1843 - accuracy: 0.0687\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1562 - accuracy: 0.1057\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1468 - accuracy: 0.1079\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1605 - accuracy: 0.0754\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1632 - accuracy: 0.1520\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1485 - accuracy: 0.1373\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1446 - accuracy: 0.1488\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1480 - accuracy: 0.1831\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1316 - accuracy: 0.2100\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1413 - accuracy: 0.2327\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1370 - accuracy: 0.2440\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1335 - accuracy: 0.2580\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1292 - accuracy: 0.2424\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1283 - accuracy: 0.2307\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1262 - accuracy: 0.2633\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1320 - accuracy: 0.2107\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1248 - accuracy: 0.2633\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1268 - accuracy: 0.2494\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1230 - accuracy: 0.2655\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1201 - accuracy: 0.2559\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1175 - accuracy: 0.2442\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1200 - accuracy: 0.2724\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1137 - accuracy: 0.2576\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1132 - accuracy: 0.2881\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1117 - accuracy: 0.2999\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1128 - accuracy: 0.2951\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1113 - accuracy: 0.2519\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1117 - accuracy: 0.2698\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1108 - accuracy: 0.2438\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1118 - accuracy: 0.2579\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1105 - accuracy: 0.2922\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1105 - accuracy: 0.2458\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1075 - accuracy: 0.2939\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1059 - accuracy: 0.2913\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1045 - accuracy: 0.2587\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1045 - accuracy: 0.3061\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1027 - accuracy: 0.3462\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1040 - accuracy: 0.3046\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1028 - accuracy: 0.3321\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1031 - accuracy: 0.3161\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1001 - accuracy: 0.3830\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1012 - accuracy: 0.3607\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0978 - accuracy: 0.4132\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3863\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0963 - accuracy: 0.4376\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0974 - accuracy: 0.4030\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0963 - accuracy: 0.4095\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0955 - accuracy: 0.4231\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0937 - accuracy: 0.4526\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0929 - accuracy: 0.4368\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0905 - accuracy: 0.4958\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0891 - accuracy: 0.5250\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0872 - accuracy: 0.5394\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0866 - accuracy: 0.5182\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0914 - accuracy: 0.4631\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0902 - accuracy: 0.4901\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0849 - accuracy: 0.5283\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0845 - accuracy: 0.5483\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0872 - accuracy: 0.4832\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0842 - accuracy: 0.5311\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0814 - accuracy: 0.5293\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0813 - accuracy: 0.5263\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0796 - accuracy: 0.5381\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0810 - accuracy: 0.5325\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0747 - accuracy: 0.5828\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0736 - accuracy: 0.5768\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0737 - accuracy: 0.5760\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0715 - accuracy: 0.5873\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0780 - accuracy: 0.5418\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0736 - accuracy: 0.5458\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0711 - accuracy: 0.5831\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0724 - accuracy: 0.5614\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0704 - accuracy: 0.5801\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0683 - accuracy: 0.5840\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0650 - accuracy: 0.6170\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0653 - accuracy: 0.5962\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0598 - accuracy: 0.6201\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0704 - accuracy: 0.5463\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0613 - accuracy: 0.6015\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0626 - accuracy: 0.5776\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0630 - accuracy: 0.5820\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0570 - accuracy: 0.6333\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0554 - accuracy: 0.6242\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0521 - accuracy: 0.6716\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0527 - accuracy: 0.6556\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0508 - accuracy: 0.6508\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0528 - accuracy: 0.6534\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0510 - accuracy: 0.6369\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0479 - accuracy: 0.6434\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0513 - accuracy: 0.6343\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0449 - accuracy: 0.6434\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0458 - accuracy: 0.6373\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0420 - accuracy: 0.6373\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0433 - accuracy: 0.6273\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0384 - accuracy: 0.6352\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0376 - accuracy: 0.6317\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0362 - accuracy: 0.6482\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0362 - accuracy: 0.6226\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0359 - accuracy: 0.6161\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0366 - accuracy: 0.6286\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0278 - accuracy: 0.6551\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0354 - accuracy: 0.6135\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0322 - accuracy: 0.6208\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0258 - accuracy: 0.6195\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0255 - accuracy: 0.6295\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0114 - accuracy: 0.6764\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0236 - accuracy: 0.6117\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0180 - accuracy: 0.6317\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0228 - accuracy: 0.6009\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0209 - accuracy: 0.5918\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0171 - accuracy: 0.6260\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0136 - accuracy: 0.6365\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0101 - accuracy: 0.6282\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0048 - accuracy: 0.6430\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0028 - accuracy: 0.6560\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0055 - accuracy: 0.6226\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9910 - accuracy: 0.6703\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9962 - accuracy: 0.6642\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0046 - accuracy: 0.6256\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.5770\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.9986 - accuracy: 0.6000\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9958 - accuracy: 0.6056\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9854 - accuracy: 0.6486\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9893 - accuracy: 0.5987\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9870 - accuracy: 0.6321\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9712 - accuracy: 0.6538\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9812 - accuracy: 0.6091\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9753 - accuracy: 0.6599\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9767 - accuracy: 0.6434\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9685 - accuracy: 0.6590\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9747 - accuracy: 0.6256\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9724 - accuracy: 0.6148\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9673 - accuracy: 0.6017\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9552 - accuracy: 0.6417\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9567 - accuracy: 0.6500\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9592 - accuracy: 0.6482\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9503 - accuracy: 0.6521\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9468 - accuracy: 0.6378\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.6265\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9465 - accuracy: 0.6348\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9541 - accuracy: 0.6070\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9374 - accuracy: 0.6556\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9300 - accuracy: 0.6187\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9341 - accuracy: 0.6343\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9249 - accuracy: 0.6517\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9215 - accuracy: 0.6531\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9291 - accuracy: 0.6258\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9291 - accuracy: 0.6553\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9206 - accuracy: 0.6484\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9233 - accuracy: 0.6649\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9003 - accuracy: 0.7018\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9241 - accuracy: 0.5859\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8939 - accuracy: 0.6727\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9154 - accuracy: 0.6623\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8913 - accuracy: 0.6714\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9084 - accuracy: 0.6684\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.6749\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9058 - accuracy: 0.6592\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8976 - accuracy: 0.6488\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8902 - accuracy: 0.6380\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8864 - accuracy: 0.6723\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8664 - accuracy: 0.6749\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8697 - accuracy: 0.6710\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8864 - accuracy: 0.6233\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8717 - accuracy: 0.6905\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.8800 - accuracy: 0.6463\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8665 - accuracy: 0.7031\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8627 - accuracy: 0.6814\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8763 - accuracy: 0.6458\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8778 - accuracy: 0.6576\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8531 - accuracy: 0.7031\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8603 - accuracy: 0.6897\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8715 - accuracy: 0.6532\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8477 - accuracy: 0.6454\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8409 - accuracy: 0.6879\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8434 - accuracy: 0.7040\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8529 - accuracy: 0.6615\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8464 - accuracy: 0.6484\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8348 - accuracy: 0.6888\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8303 - accuracy: 0.6706\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8190 - accuracy: 0.6836\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8221 - accuracy: 0.6788\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8331 - accuracy: 0.6675\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8478 - accuracy: 0.6454\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8312 - accuracy: 0.6510\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8192 - accuracy: 0.6758\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8148 - accuracy: 0.6788\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8093 - accuracy: 0.6918\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8062 - accuracy: 0.6771\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8150 - accuracy: 0.6484\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7933 - accuracy: 0.6884\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8263 - accuracy: 0.6697\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8062 - accuracy: 0.6693\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7972 - accuracy: 0.7027\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8149 - accuracy: 0.6567\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7925 - accuracy: 0.6402\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8071 - accuracy: 0.6471\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8238 - accuracy: 0.6693\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7960 - accuracy: 0.6168\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7911 - accuracy: 0.6641\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7788 - accuracy: 0.6554\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.7023\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7886 - accuracy: 0.6246\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7711 - accuracy: 0.6714\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7895 - accuracy: 0.6749\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7606 - accuracy: 0.6497\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7756 - accuracy: 0.6953\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7463 - accuracy: 0.6931\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7639 - accuracy: 0.6745\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7567 - accuracy: 0.6889\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7614 - accuracy: 0.6789\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7983 - accuracy: 0.6568\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7577 - accuracy: 0.6828\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7614 - accuracy: 0.6399\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7441 - accuracy: 0.6877\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7590 - accuracy: 0.7028\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7290 - accuracy: 0.7089\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7708 - accuracy: 0.6651\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.6746\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7546 - accuracy: 0.6503\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7457 - accuracy: 0.6955\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.7120\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.7241\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.6695\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7234 - accuracy: 0.6777\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7274 - accuracy: 0.6829\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7160 - accuracy: 0.7302\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.6909\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7287 - accuracy: 0.7195\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7133 - accuracy: 0.7325\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.7060\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.7173\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.7082\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7078 - accuracy: 0.7117\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.7412\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.7520\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7301 - accuracy: 0.6804\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7060 - accuracy: 0.7113\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.6970\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7136 - accuracy: 0.6939\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7190 - accuracy: 0.6848\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7134 - accuracy: 0.7113\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.7009\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.7509\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7146 - accuracy: 0.6840\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.7326\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.6706\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.7079\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.7192\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.7144\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.7426\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.7522\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.7492\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.7162\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.7670\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.7322\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6860 - accuracy: 0.7102\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.7388\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6819 - accuracy: 0.7418\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.7466\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.7549\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6761 - accuracy: 0.7380\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6875 - accuracy: 0.7497\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.7042\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.7636\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.7667\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.7120\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.7358\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.7597\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.7623\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.7532\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.7449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39fd802d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G84gCltMBi_4"
      },
      "source": [
        "model.save(\"final_iris_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2W2F80WBi_5"
      },
      "source": [
        "### Saving Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmwtXNebBi_6"
      },
      "source": [
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDgV5sbXBi_7",
        "outputId": "672d5f51-973c-412d-eff9-53f5caae5bd3"
      },
      "source": [
        "joblib.dump(scaler,'iris_scaler.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iris_scaler.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a78OuLLKBi_8"
      },
      "source": [
        "## Predicting a Single New Flower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmiPorOjBi_9"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIscdsEuBi_9"
      },
      "source": [
        "flower_model = load_model(\"final_iris_model.h5\")\n",
        "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "om8JAgcJBi_-",
        "outputId": "2a8439d2-2642-4938-dc89-e9f70ad3d282"
      },
      "source": [
        "iris.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3MpOVLBBi__"
      },
      "source": [
        "flower_example = {'sepal_length':5.1,\n",
        "                 'sepal_width':3.5,\n",
        "                 'petal_length':1.4,\n",
        "                 'petal_width':0.2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRWigLE4Bi__",
        "outputId": "9201f846-3784-4b00-d491-f4b34c61a659"
      },
      "source": [
        "flower_example.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy3LUpktBi__",
        "outputId": "58f1b430-ffb7-4fad-8d90-a6b44719b37a"
      },
      "source": [
        "encoder.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIxW_OCwBjAA"
      },
      "source": [
        "def return_prediction(model,scaler,sample_json):\n",
        "    \n",
        "    # For larger data features, you should probably write a for loop\n",
        "    # That builds out this array for you\n",
        "    \n",
        "    s_len = sample_json['sepal_length']\n",
        "    s_wid = sample_json['sepal_width']\n",
        "    p_len = sample_json['petal_length']\n",
        "    p_wid = sample_json['petal_width']\n",
        "    \n",
        "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
        "    \n",
        "    flower = scaler.transform(flower)\n",
        "    \n",
        "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
        "    \n",
        "    class_ind = model.predict_classes(flower)\n",
        "    \n",
        "    return classes[class_ind][0]\n",
        "                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StdH_2m3j118"
      },
      "source": [
        "import joblib\n",
        "import pickle\n",
        "\n",
        "\n",
        "# model = pickle.dump(model,open('model.'))\n",
        "pickle.dump(model,open('model.pkl','wb'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "wYVPaXrwBjAA",
        "outputId": "46f060c9-5865-42c6-9bdd-6395a8b43b55"
      },
      "source": [
        "return_prediction(flower_model,flower_scaler,flower_example)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'setosa'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-UHDWMmBjAB"
      },
      "source": [
        "# CODE FOR DEPLOYMENT:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnTzJiVWBjAB"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "\n",
        "flower_model = load_model(\"final_iris_model.h5\")\n",
        "flower_scaler = joblib.load(\"iris_scaler.pkl\")\n",
        "\n",
        "\n",
        "def return_prediction(model,scaler,sample_json):\n",
        "    \n",
        "    # For larger data features, you should probably write a for loop\n",
        "    # That builds out this array for you\n",
        "    \n",
        "    s_len = sample_json['sepal_length']\n",
        "    s_wid = sample_json['sepal_width']\n",
        "    p_len = sample_json['petal_length']\n",
        "    p_wid = sample_json['petal_width']\n",
        "    \n",
        "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
        "    \n",
        "    flower = scaler.transform(flower)\n",
        "    \n",
        "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
        "    \n",
        "    class_ind = model.predict_classes(flower)\n",
        "    \n",
        "    return classes[class_ind][0]\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjVQm_8QBjAC"
      },
      "source": [
        "flower_example = {\n",
        "\"sepal_length\":5.1,\n",
        "\"sepal_width\":3.5,\n",
        "\"petal_length\":1.4,\n",
        "\"petal_width\":0.2\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI3ViYENvCiK"
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QhT5W02vEgU"
      },
      "source": [
        "# result = requests.post(\"http://locpspdfkitalhost:5000/api/flower\",json = flower_example)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJu9xSlYvNfW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}